{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import option_context\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the main notebook for topic modeling and sentiment analysis (version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97188, 24)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[['username','tweet']].copy()\n",
    "df_analysis.dropna(inplace=True)\n",
    "df_analysis.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop.extend(['hi', 'hey', 'hello','ha', 'followed','wa','dm','dont','cant','wont','get','still','like','need',\n",
    "            'someone','people','im','ive','month','week','day','could','give','want','please','pls','since','one',\n",
    "             'back','thanks','thank','take','doesnt','does', 'might', 'must','lock','access','sent','closed','use',\n",
    "            'u','contact','new','email','time','message','tried','answer','waiting','issue','reason','going',\n",
    "            'work','agent','bank','card','trying','even','every'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extend for most common English adverbs\n",
    "\n",
    "stop.extend(['up','so','out','just','now','how','then','more','also','here',\n",
    "            'well','only','very','even','back','there','down','still','in',\n",
    "            'as','to','when','never','really','most','on','why','about','over',\n",
    "            'again','where','right','off','always','today','all','far','long',\n",
    "            'away','yet','often','ever','however','almost','later','much',\n",
    "            'once','least','ago','together','around','already','enough','both',\n",
    "            'maybe','actually','probably','home','of course','perhaps','little',\n",
    "            'else','sometimes','finally','less','better','early','especially',\n",
    "            'either','quite','simply','nearly','soon','certainly','quickly',\n",
    "            'no','recently','before','usually','thus','exactly','hard',\n",
    "            'particularly','pretty','forward','ok','okay','clearly','indeed',\n",
    "            'rather','that','tonight','close','suddenly','best','instead',\n",
    "            'ahead','fast','alone','eventually','directly'])\n",
    "\n",
    "# # Extend for most common irregular verbs (except pay,lose,send,buy,spend)\n",
    "\n",
    "stop.extend(['say','make','go','take','come','see','know','get','got','give',\n",
    "            'find','think','tell','become','show','leave','feel','put','bring',\n",
    "            'begin','keep','hold','write','stand','hear','let','mean','set','meet',\n",
    "            'run','sit','speak','lie','lead','read','grow','fall',\n",
    "            'build','understand','draw','break','cut','rise','drive','wear',\n",
    "            'choose'])\n",
    "\n",
    "# ## Extend for prepositions\n",
    "stop.extend(['without','among'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_compounds = (lambda x: \n",
    "                 x.replace('debit card', 'debitcard')\n",
    "                 .replace('rainbow card', 'debitcard')\n",
    "                 .replace('bank card', 'debitcard')\n",
    "                 .replace('revolut card', 'debitcard')\n",
    "                 .replace('revcards', 'debitcard')\n",
    "                 .replace('debitcardcrypto', 'debitcard crypto')\n",
    "                 .replace('credit card', 'creditcard')\n",
    "                 .replace('junior card', 'juniorcard')\n",
    "                 .replace('revolut junior', 'juniorcard')\n",
    "                 .replace('revolut youth', 'juniorcard')\n",
    "                 .replace('junior accounts', 'juniorcard')\n",
    "                 .replace('junior account', 'juniorcard')\n",
    "                 .replace('business account', 'budinessaccount')\n",
    "                 .replace('savings account', 'savingsaccount')\n",
    "                 .replace('bank account', 'bankaccount')\n",
    "                 .replace('premium account', 'premiumaccount')\n",
    "                 .replace('revolut premium', 'premiumaccount')\n",
    "                 .replace('premium user', 'premiumaccount')\n",
    "                 .replace('premium plan', 'premiumaccount')\n",
    "                 .replace('premium membership', 'premiumaccount')\n",
    "                 .replace('premium member', 'premiumaccount')\n",
    "                 .replace('premium paid', 'premiumaccount')\n",
    "                 .replace('premium payment', 'premiumaccount')\n",
    "                 .replace('mypremiumaccountworthnothing', 'my premiumaccount worth nothing')\n",
    "                 .replace('premium service', 'premiumaccount service')\n",
    "                 .replace('metal account', 'metalaccount')\n",
    "                 .replace('metal plan', 'metalaccount')\n",
    "                 .replace('metal customer', 'metalaccount')\n",
    "                 .replace('metal card', 'metalaccount')\n",
    "                 .replace('metal customers', 'metalaccount')\n",
    "                 .replace('metal user', 'metalaccount')\n",
    "                 .replace('business bank', 'businessbank')\n",
    "                 .replace('virtual card', 'virtualcard')\n",
    "                 .replace('revolut business', 'revolutbusiness')\n",
    "                 .replace('google pay', 'googlepay')\n",
    "                 .replace('apple pay', 'applepay')\n",
    "                 .replace('apple wallet', 'applepay')\n",
    "                 .replace('applepayment', 'applepay')\n",
    "                 .replace('samsung pay', 'samsungpay')\n",
    "                 .replace('cryptocurrency', 'crypto')\n",
    "                 .replace('cryptorelated', 'crypto related')\n",
    "                 .replace('cryptofriendly', 'crypto friendly')\n",
    "                 .replace('criptos', 'crypto')\n",
    "                 .replace('cripto', 'crypto')\n",
    "                 .replace('cryptos', 'crypto')\n",
    "                 .replace('cryptoasset', 'crypto')\n",
    "                 .replace('doge coin', 'crypto')\n",
    "                 .replace(' doge ', ' crypto ')\n",
    "                 .replace('customer service', 'customerservice')\n",
    "                 .replace('supoort', 'support')\n",
    "                 .replace('customer support', 'customerservice')\n",
    "                 .replace(' cs ', ' customerservice ')\n",
    "                 .replace('phone number', 'phonenumber')\n",
    "                 .replace('social media', 'socialmedia')\n",
    "                 .replace('app chat', 'appchat')\n",
    "                 .replace('challenger bank', 'fintech')\n",
    "                 .replace('challengerbank', 'fintech')\n",
    "                 .replace('neobanking', 'fintech')\n",
    "                 .replace('neobanks', 'fintech')\n",
    "                 .replace('neobank', 'fintech')\n",
    "                 .replace('transferthis', 'transfer')\n",
    "                 .replace('application', 'app')\n",
    "                 .replace('locked', 'lock')\n",
    "                 .replace('unlock', 'lock')\n",
    "                 .replace('block', 'lock')\n",
    "                 .replace('dark mode', 'darkmode')\n",
    "                 .replace('dark theme', 'darkmode')\n",
    "                 .replace('xfers', 'transfer')\n",
    "                 .replace('xfer', 'transfer'))\n",
    "\n",
    "\n",
    "df_analysis['tweet_compound'] = df_analysis.tweet.map(create_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "lemma = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for tweet in df_analysis['tweet_compound']:\n",
    "    tweet = lemma.lemmatize(tweet)\n",
    "    tweet = TextBlob(tweet).words  # tokenize words\n",
    "    tweet = [w for w in tweet if w not in stop]\n",
    "\n",
    "    counter += Counter(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32679"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             account 28824\n",
      "             revolut 16947\n",
      "                 app 16179\n",
      "               money 15512\n",
      "                help 12070\n",
      "                chat 7711\n",
      "             support 5474\n",
      "                days 5372\n",
      "               would 4011\n",
      "              months 3516\n"
     ]
    }
   ],
   "source": [
    "for phrase, count in counter.most_common(10):\n",
    "    print('%20s %i' % (\"\".join(phrase), count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tawneykirkland/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'course', 'doe', 'le', \"n't\", 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(97188, 13102)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "    \n",
    "vectorizer = CountVectorizer(tokenizer = LemmaTokenizer(),\n",
    "                              stop_words = stop,\n",
    "                              min_df=2,\n",
    "                              max_df = 0.9)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(df_analysis.tweet_compound)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97188, 5)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(5)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 13102)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['account', 'fund', 'chat', 'document', 'open', 'information'],\n",
       " ['app', 'support', 'phone', 'chat', 'log', 'problem'],\n",
       " ['revolut', 'crypto', 'customer', 'child', 'fintech', 'transfer'],\n",
       " ['money', 'transfer', 'send', 'pay', 'bankaccount', 'lost'],\n",
       " ['help', 'chat', 'live', 'support', 'hour', 'problem']]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-7:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Component 0 (topic 1) seems to be about account queries\n",
    "- Component 1 (topic 2) seems to be about app-related queries\n",
    "- Component 2 (topic 3) seems to be about fintech innovations\n",
    "- Component 3 (topic 4) is about transfers and not being able to access accounts / money\n",
    "- Component 4 (topic 5) is about general requests for support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['topic'] = doc_topic.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_compound</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>elpublloret</td>\n",
       "      <td>hi how can i change my pin when i cant remember my old pin please</td>\n",
       "      <td>hi how can i change my pin when i cant remember my old pin please</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23520</th>\n",
       "      <td>nunoamo33671947</td>\n",
       "      <td>anything i can do on my end to speed this up</td>\n",
       "      <td>anything i can do on my end to speed this up</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14587</th>\n",
       "      <td>_rinakay</td>\n",
       "      <td>omg what that is awful  sucks that happened to you surely that must be illegalyou can report it somewhere</td>\n",
       "      <td>omg what that is awful  sucks that happened to you surely that must be illegalyou can report it somewhere</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47101</th>\n",
       "      <td>iskeyrol</td>\n",
       "      <td>did they manage to fix your account</td>\n",
       "      <td>did they manage to fix your account</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86973</th>\n",
       "      <td>auduccio_</td>\n",
       "      <td>ill contact them then thank you</td>\n",
       "      <td>ill contact them then thank you</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              username  \\\n",
       "14997      elpublloret   \n",
       "23520  nunoamo33671947   \n",
       "14587         _rinakay   \n",
       "47101         iskeyrol   \n",
       "86973        auduccio_   \n",
       "\n",
       "                                                                                                           tweet  \\\n",
       "14997                                          hi how can i change my pin when i cant remember my old pin please   \n",
       "23520                                                               anything i can do on my end to speed this up   \n",
       "14587  omg what that is awful  sucks that happened to you surely that must be illegalyou can report it somewhere   \n",
       "47101                                                                        did they manage to fix your account   \n",
       "86973                                                                            ill contact them then thank you   \n",
       "\n",
       "                                                                                                  tweet_compound  \\\n",
       "14997                                          hi how can i change my pin when i cant remember my old pin please   \n",
       "23520                                                               anything i can do on my end to speed this up   \n",
       "14587  omg what that is awful  sucks that happened to you surely that must be illegalyou can report it somewhere   \n",
       "47101                                                                        did they manage to fix your account   \n",
       "86973                                                                            ill contact them then thank you   \n",
       "\n",
       "       topic  \n",
       "14997      1  \n",
       "23520      2  \n",
       "14587      3  \n",
       "47101      0  \n",
       "86973      3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with option_context('display.max_colwidth', 600):\n",
    "    display(df_analysis.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "sentiment = []\n",
    "for tweet in df_analysis.tweet_compound:\n",
    "    sentiment.append(sid_obj.polarity_scores(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.138</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.000  0.722  0.278    0.4019\n",
       "1  0.329  0.671  0.000   -0.9136\n",
       "2  0.138  0.862  0.000   -0.7269\n",
       "3  0.000  0.952  0.048    0.2023\n",
       "4  0.139  0.696  0.165   -0.1531"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = pd.DataFrame(sentiment)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df_analysis, sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([df,merged_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis - high level topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add month feature to enable analysis over time\n",
    "full_df['month'] = pd.DatetimeIndex(full_df['date']).month\n",
    "full_df['day'] = pd.DatetimeIndex(full_df['date']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>...</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_compound</th>\n",
       "      <th>topic</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88789</th>\n",
       "      <td>206952</td>\n",
       "      <td>1230603091352936449</td>\n",
       "      <td>1230603091352936449</td>\n",
       "      <td>2020-02-20 16:20:15 EST</td>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>16:20:15</td>\n",
       "      <td>-500</td>\n",
       "      <td>240235447</td>\n",
       "      <td>pabloasensiouk</td>\n",
       "      <td>pure joy kuddos to    revolut hijacked a monzo twitter thread and things got weird really fast    fintech socialmedia</td>\n",
       "      <td>...</td>\n",
       "      <td>pabloasensiouk</td>\n",
       "      <td>pure joy kuddos to    revolut hijacked a monzo twitter thread and things got weird really fast    fintech socialmedia</td>\n",
       "      <td>pure joy kuddos to    revolut hijacked a monzo twitter thread and things got weird really fast    fintech socialmedia</td>\n",
       "      <td>2</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42653</th>\n",
       "      <td>113345</td>\n",
       "      <td>1286706949153849345</td>\n",
       "      <td>1286605753575497729</td>\n",
       "      <td>2020-07-24 12:56:57 EDT</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>12:56:57</td>\n",
       "      <td>-500</td>\n",
       "      <td>1859656675</td>\n",
       "      <td>drashyagoel</td>\n",
       "      <td>it looked like a very commerciallybent decision to me addon products like crypto trading were moved closer to the home screen  while your spending behaviour and savings were moved farther</td>\n",
       "      <td>...</td>\n",
       "      <td>drashyagoel</td>\n",
       "      <td>it looked like a very commerciallybent decision to me addon products like crypto trading were moved closer to the home screen  while your spending behaviour and savings were moved farther</td>\n",
       "      <td>it looked like a very commerciallybent decision to me addon products like crypto trading were moved closer to the home screen  while your spending behaviour and savings were moved farther</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                   id      conversation_id  \\\n",
       "88789      206952  1230603091352936449  1230603091352936449   \n",
       "42653      113345  1286706949153849345  1286605753575497729   \n",
       "\n",
       "                    created_at        date      time  timezone     user_id  \\\n",
       "88789  2020-02-20 16:20:15 EST  2020-02-20  16:20:15      -500   240235447   \n",
       "42653  2020-07-24 12:56:57 EDT  2020-07-24  12:56:57      -500  1859656675   \n",
       "\n",
       "             username  \\\n",
       "88789  pabloasensiouk   \n",
       "42653     drashyagoel   \n",
       "\n",
       "                                                                                                                                                                                             tweet  \\\n",
       "88789                                                                        pure joy kuddos to    revolut hijacked a monzo twitter thread and things got weird really fast    fintech socialmedia   \n",
       "42653  it looked like a very commerciallybent decision to me addon products like crypto trading were moved closer to the home screen  while your spending behaviour and savings were moved farther   \n",
       "\n",
       "       ...        username  \\\n",
       "88789  ...  pabloasensiouk   \n",
       "42653  ...     drashyagoel   \n",
       "\n",
       "                                                                                                                                                                                             tweet  \\\n",
       "88789                                                                        pure joy kuddos to    revolut hijacked a monzo twitter thread and things got weird really fast    fintech socialmedia   \n",
       "42653  it looked like a very commerciallybent decision to me addon products like crypto trading were moved closer to the home screen  while your spending behaviour and savings were moved farther   \n",
       "\n",
       "                                                                                                                                                                                    tweet_compound  \\\n",
       "88789                                                                        pure joy kuddos to    revolut hijacked a monzo twitter thread and things got weird really fast    fintech socialmedia   \n",
       "42653  it looked like a very commerciallybent decision to me addon products like crypto trading were moved closer to the home screen  while your spending behaviour and savings were moved farther   \n",
       "\n",
       "      topic    neg    neu    pos compound month day  \n",
       "88789     2  0.079  0.744  0.177   0.4767     2  20  \n",
       "42653     2  0.000  0.848  0.152   0.6124     7  24  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with option_context('display.max_colwidth', 600):\n",
    "    display(full_df[(full_df['topic']==2)].sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic  month\n",
       "0      1        0.033938\n",
       "       2        0.024787\n",
       "       3        0.021817\n",
       "       4        0.030276\n",
       "       5        0.037097\n",
       "       6       -0.016794\n",
       "       7        0.014467\n",
       "       8        0.011020\n",
       "       9        0.032301\n",
       "       10       0.043128\n",
       "       11       0.023449\n",
       "       12       0.039786\n",
       "1      1        0.070382\n",
       "       2        0.074837\n",
       "       3        0.093229\n",
       "       4        0.046080\n",
       "       5        0.070670\n",
       "       6        0.045055\n",
       "       7        0.076895\n",
       "       8        0.087954\n",
       "       9        0.063721\n",
       "       10       0.086634\n",
       "       11       0.061015\n",
       "       12       0.077712\n",
       "2      1        0.117221\n",
       "       2        0.185554\n",
       "       3        0.162885\n",
       "       4        0.131136\n",
       "       5        0.118165\n",
       "       6        0.082941\n",
       "       7        0.170698\n",
       "       8        0.104704\n",
       "       9        0.143378\n",
       "       10       0.135509\n",
       "       11       0.061563\n",
       "       12       0.164905\n",
       "3      1       -0.043102\n",
       "       2       -0.022411\n",
       "       3        0.023103\n",
       "       4       -0.045292\n",
       "       5       -0.055451\n",
       "       6       -0.075517\n",
       "       7       -0.026238\n",
       "       8       -0.055134\n",
       "       9       -0.048467\n",
       "       10      -0.001936\n",
       "       11      -0.038897\n",
       "       12      -0.021349\n",
       "4      1        0.215663\n",
       "       2        0.226929\n",
       "       3        0.226780\n",
       "       4        0.211212\n",
       "       5        0.209488\n",
       "       6        0.193029\n",
       "       7        0.213500\n",
       "       8        0.228716\n",
       "       9        0.217894\n",
       "       10       0.229742\n",
       "       11       0.226882\n",
       "       12       0.228647\n",
       "Name: compound, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby(['topic','month'])['compound'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "0    14725\n",
       "1    25697\n",
       "2    22151\n",
       "3    15667\n",
       "4    18948\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby('topic')['topic'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97188, 34)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to csv for Tableau analysis\n",
    "#full_df.to_csv('datatableau.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charles94240716"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFI-DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display top n terms associated with each topic\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tawneykirkland/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'course', \"n't\", 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97188, 14535)\n"
     ]
    }
   ],
   "source": [
    "# tuning vectorizer params\n",
    "tf_idf = TfidfVectorizer(stop_words=stop,\n",
    "                         tokenizer=word_tokenize,\n",
    "                         min_df= 2,\n",
    "                         max_df= 0.9)\n",
    "\n",
    "# document-term matrix\n",
    "doc_word2 = tf_idf.fit_transform(df_analysis.tweet_compound)\n",
    "print(doc_word2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "account, months, weeks, days, funds\n",
      "\n",
      "Topic  1\n",
      "help, revolut, problem, log, anyone\n",
      "\n",
      "Topic  2\n",
      "app, log, phone, support, problem\n",
      "\n",
      "Topic  3\n",
      "money, revolut, send, transfer, months\n",
      "\n",
      "Topic  4\n",
      "chat, live, reply, days, support\n"
     ]
    }
   ],
   "source": [
    "n = 5 # number of topics\n",
    "\n",
    "# model selection, fit/trans, and hyperparameter tuning\n",
    "nmf_model_2 = NMF(n_components =n)\n",
    "\n",
    "# doc-topic matrix\n",
    "doc_topic2 = nmf_model_2.fit_transform(doc_word2)\n",
    "\n",
    "# creating ids for each topic\n",
    "topic_ids2 = [\"topic\"+str(val) for val in range(n)]\n",
    "\n",
    "# topic-term matrix\n",
    "topic_word2 = pd.DataFrame(nmf_model_2.components_.round(n),\n",
    "             index = topic_ids2,\n",
    "             columns = tf_idf.get_feature_names())\n",
    "\n",
    "# prints top x words in each topic\n",
    "display_topics(nmf_model_2, \n",
    "               tf_idf.get_feature_names(), \n",
    "               5) # number of top words/topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test6.to_csv('test6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intent = pd.read_csv('training_base.csv',\n",
    "                       usecols = ['username','tweet','intent'])\n",
    "\n",
    "def remove_space(text):\n",
    "    text = text.strip()\n",
    "    return text\n",
    "    \n",
    "df_intent['tweet'] = df_intent.tweet.map(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['key'] = merged_df['username'] + merged_df['tweet']\n",
    "d = merged_df[~merged_df['key'].isin(df_intent['username'] + df_intent['tweet'])].drop(['key'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1, test1 = train_test_split(d,train_size=200,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1.to_csv('training_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
