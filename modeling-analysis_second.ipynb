{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import option_context\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the main notebook for topic modeling and sentiment analysis (version 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99296, 24)"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[['username','tweet']].copy()\n",
    "df_analysis.dropna(inplace=True)\n",
    "df_analysis.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop.extend(['hi', 'hey', 'hello','ha', 'followed','wa','dm','dont','cant','wont','get','still','like','need',\n",
    "            'someone','people','im','ive','month','week','day','could','give','want','please','pls','since','one',\n",
    "             'back','thanks','thank','take'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extend for most common English adverbs\n",
    "\n",
    "stop.extend(['up','so','out','just','now','how','then','more','also','here',\n",
    "            'well','only','very','even','back','there','down','still','in',\n",
    "            'as','to','when','never','really','most','on','why','about','over',\n",
    "            'again','where','right','off','always','today','all','far','long',\n",
    "            'away','yet','often','ever','however','almost','later','much',\n",
    "            'once','least','ago','together','around','already','enough','both',\n",
    "            'maybe','actually','probably','home','of course','perhaps','little',\n",
    "            'else','sometimes','finally','less','better','early','especially',\n",
    "            'either','quite','simply','nearly','soon','certainly','quickly',\n",
    "            'no','recently','before','usually','thus','exactly','hard',\n",
    "            'particularly','pretty','forward','ok','okay','clearly','indeed',\n",
    "            'rather','that','tonight','close','suddenly','best','instead',\n",
    "            'ahead','fast','alone','eventually','directly'])\n",
    "\n",
    "# # Extend for most common irregular verbs (except pay,lose,send,buy,spend)\n",
    "\n",
    "stop.extend(['say','make','go','take','come','see','know','get','got','give',\n",
    "            'find','think','tell','become','show','leave','feel','put','bring',\n",
    "            'begin','keep','hold','write','stand','hear','let','mean','set','meet',\n",
    "            'run','sit','speak','lie','lead','read','grow','fall',\n",
    "            'build','understand','draw','break','cut','rise','drive','wear',\n",
    "            'choose'])\n",
    "\n",
    "# ## Extend for prepositions\n",
    "stop.extend(['without','among'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_compounds = (lambda x: \n",
    "                 x.replace('debit card', 'debitcard')\n",
    "                 .replace('rainbow card', 'debitcard')\n",
    "                 .replace('bank card', 'debitcard')\n",
    "                 .replace('revolut card', 'debitcard')\n",
    "                 .replace('revcards', 'debitcard')\n",
    "                 .replace('credit card', 'creditcard')\n",
    "                 .replace('junior card', 'juniorcard')\n",
    "                 .replace('revolut junior', 'juniorcard')\n",
    "                 .replace('business account', 'budinessaccount')\n",
    "                 .replace('savings account', 'savingsaccount')\n",
    "                 .replace('bank account', 'bankaccount')\n",
    "                 .replace('premium account', 'premiumaccount')\n",
    "                 .replace('premium user', 'premiumaccount')\n",
    "                 .replace('premium plan', 'premiumaccount')\n",
    "                 .replace('metal account', 'metalaccount')\n",
    "                 .replace('metal card', 'metalaccount')\n",
    "                 .replace('metal customers', 'metalaccount')\n",
    "                 .replace('metal user', 'metalaccount')\n",
    "                 .replace('business bank', 'businessbank')\n",
    "                 .replace('virtual card', 'virtualcard')\n",
    "                 .replace('revolut business', 'revolutbusiness')\n",
    "                 .replace('google pay', 'googlepay')\n",
    "                 .replace('apple pay', 'applepay')\n",
    "                 .replace('applepayment', 'applepay')\n",
    "                 .replace('samsung pay', 'samsungpay')\n",
    "                 .replace('cryptocurrency', 'crypto')\n",
    "                 .replace('cryptos', 'crypto')\n",
    "                 .replace('cryptoasset', 'crypto')\n",
    "                 .replace('doge coin', 'crypto')\n",
    "                 .replace(' doge ', ' crypto ')\n",
    "                 .replace('customer service', 'customerservice')\n",
    "                 .replace('supoort', 'support')\n",
    "                 .replace('customer support', 'customerservice')\n",
    "                 .replace(' cs ', ' customerservice ')\n",
    "                 .replace('phone number', 'phonenumber')\n",
    "                 .replace('social media', 'socialmedia')\n",
    "                 .replace('app chat', 'appchat')\n",
    "                 .replace('challenger bank', 'fintech')\n",
    "                 .replace('challengerbank', 'fintech')\n",
    "                 .replace('neobanking', 'fintech')\n",
    "                 .replace('neobanks', 'fintech')\n",
    "                 .replace('neobank', 'fintech')\n",
    "                 .replace('transferthis', 'transfer')\n",
    "                 .replace('application', 'app')\n",
    "                 .replace('locked', 'lock')\n",
    "                 .replace('unlock', 'lock')\n",
    "                 .replace('block', 'lock')\n",
    "                 .replace('dark mode', 'darkmode')\n",
    "                 .replace('wealth management', 'wealthmanagement'))\n",
    "\n",
    "\n",
    "df_analysis['tweet_compound'] = df_analysis.tweet.map(create_compounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "lemma = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for tweet in df_analysis['tweet_compound']:\n",
    "    tweet = lemma.lemmatize(tweet)\n",
    "    tweet = TextBlob(tweet).words  # tokenize words\n",
    "    tweet = [w for w in tweet if w not in stop]\n",
    "\n",
    "    counter += Counter(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32774"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             account 29068\n",
      "             revolut 17033\n",
      "                 app 16213\n",
      "               money 15544\n",
      "                lock 13818\n",
      "                help 12151\n",
      "                chat 7750\n",
      "                card 6317\n",
      "              access 6215\n",
      "             support 5496\n"
     ]
    }
   ],
   "source": [
    "for phrase, count in counter.most_common(10):\n",
    "    print('%20s %i' % (\"\".join(phrase), count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tawneykirkland/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'course', 'doe', 'le', 'might', 'must', \"n't\", 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99296, 13172)"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "    \n",
    "vectorizer = CountVectorizer(tokenizer = LemmaTokenizer(),\n",
    "                              stop_words = stop,\n",
    "                              min_df=2,\n",
    "                              max_df = 0.9)\n",
    "\n",
    "doc_word = vectorizer.fit_transform(df_analysis.tweet_compound)\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99296, 5)"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model = NMF(5)\n",
    "doc_topic = nmf_model.fit_transform(doc_word)\n",
    "doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 13172)"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word = nmf_model.components_\n",
    "topic_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['account', 'lock', 'access', 'fund', 'reason', 'document'],\n",
       " ['app', 'access', 'new', 'phone', 'card', 'email'],\n",
       " ['revolut', 'bank', 'crypto', 'use', 'customer', 'fintech'],\n",
       " ['money', 'bank', 'lock', 'transfer', 'send', 'card'],\n",
       " ['help', 'chat', 'agent', 'live', 'waiting', 'support']]"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "t = nmf_model.components_.argsort(axis=1)[:,-1:-7:-1]\n",
    "topic_words = [[words[e] for e in l] for l in t]\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Component 0 (topic 1) seems to be about account queries\n",
    "- Component 1 (topic 2) seems to be about app-related queries\n",
    "- Component 2 (topic 3) seems to be about fintech payments / transactions\n",
    "- Component 3 (topic 4) is about transfers and not being able to access accounts / money\n",
    "- Component 4 (topic 5) is about general issues / requests for support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['topic'] = doc_topic.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_compound</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42283</th>\n",
       "      <td>realsemihboyuk</td>\n",
       "      <td>hi i have a authorisation transaction on my bank account that is indicate as terminate its an transport for london authorisation but i never use my revolut card on tfl card reader  my question is when i can have my money back thanks for reply</td>\n",
       "      <td>hi i have a authorisation transaction on my bankaccount that is indicate as terminate its an transport for london authorisation but i never use my debitcard on tfl card reader  my question is when i can have my money back thanks for reply</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94372</th>\n",
       "      <td>alvin06142008</td>\n",
       "      <td>hello my account has been blocked because the system couldnt verify my verification code can i seek your assistance in getting someone to assist me in the app thanks</td>\n",
       "      <td>hello my account has been lock because the system couldnt verify my verification code can i seek your assistance in getting someone to assist me in the app thanks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83676</th>\n",
       "      <td>al_shone</td>\n",
       "      <td>yep the bank  have no record of the refund but  say that the bank has accepted it so what can i do now ive had months of issues between you two and payments i think you should have a chat with each other</td>\n",
       "      <td>yep the bank  have no record of the refund but  say that the bank has accepted it so what can i do now ive had months of issues between you two and payments i think you should have a chat with each other</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90482</th>\n",
       "      <td>qstweet</td>\n",
       "      <td>what was the outcome im having yesterday too</td>\n",
       "      <td>what was the outcome im having yesterday too</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80776</th>\n",
       "      <td>fuckoff_u_cunt</td>\n",
       "      <td>can someone chat with me in dm i need help with the app and no agent from revolut is answering i need help</td>\n",
       "      <td>can someone chat with me in dm i need help with the app and no agent from revolut is answering i need help</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             username  \\\n",
       "42283  realsemihboyuk   \n",
       "94372   alvin06142008   \n",
       "83676        al_shone   \n",
       "90482         qstweet   \n",
       "80776  fuckoff_u_cunt   \n",
       "\n",
       "                                                                                                                                                                                                                                                     tweet  \\\n",
       "42283   hi i have a authorisation transaction on my bank account that is indicate as terminate its an transport for london authorisation but i never use my revolut card on tfl card reader  my question is when i can have my money back thanks for reply   \n",
       "94372                                                                                hello my account has been blocked because the system couldnt verify my verification code can i seek your assistance in getting someone to assist me in the app thanks   \n",
       "83676                                          yep the bank  have no record of the refund but  say that the bank has accepted it so what can i do now ive had months of issues between you two and payments i think you should have a chat with each other   \n",
       "90482                                                                                                                                                                                                         what was the outcome im having yesterday too   \n",
       "80776                                                                                                                                           can someone chat with me in dm i need help with the app and no agent from revolut is answering i need help   \n",
       "\n",
       "                                                                                                                                                                                                                                        tweet_compound  \\\n",
       "42283   hi i have a authorisation transaction on my bankaccount that is indicate as terminate its an transport for london authorisation but i never use my debitcard on tfl card reader  my question is when i can have my money back thanks for reply   \n",
       "94372                                                                               hello my account has been lock because the system couldnt verify my verification code can i seek your assistance in getting someone to assist me in the app thanks   \n",
       "83676                                      yep the bank  have no record of the refund but  say that the bank has accepted it so what can i do now ive had months of issues between you two and payments i think you should have a chat with each other   \n",
       "90482                                                                                                                                                                                                     what was the outcome im having yesterday too   \n",
       "80776                                                                                                                                       can someone chat with me in dm i need help with the app and no agent from revolut is answering i need help   \n",
       "\n",
       "       topic  \n",
       "42283      3  \n",
       "94372      1  \n",
       "83676      4  \n",
       "90482      4  \n",
       "80776      4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with option_context('display.max_colwidth', 600):\n",
    "    display(df_analysis.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "sentiment = []\n",
    "for tweet in df_analysis.tweet_compound:\n",
    "    sentiment.append(sid_obj.polarity_scores(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.4019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.329</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.138</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.000  0.722  0.278    0.4019\n",
       "1  0.329  0.671  0.000   -0.9136\n",
       "2  0.138  0.862  0.000   -0.7269\n",
       "3  0.000  0.952  0.048    0.2023\n",
       "4  0.139  0.696  0.165   -0.1531"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = pd.DataFrame(sentiment)\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df_analysis, sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([df,merged_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add month feature to enable analysis over time\n",
    "full_df['month'] = pd.DatetimeIndex(full_df['date']).month\n",
    "full_df['day'] = pd.DatetimeIndex(full_df['date']).day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>...</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_compound</th>\n",
       "      <th>topic</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>3465</td>\n",
       "      <td>1338853447324463106</td>\n",
       "      <td>1338511787805773826</td>\n",
       "      <td>2020-12-15 09:28:31 EST</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>09:28:31</td>\n",
       "      <td>-500</td>\n",
       "      <td>957772878132498432</td>\n",
       "      <td>delonixkidal</td>\n",
       "      <td>love for my country  best joke</td>\n",
       "      <td>...</td>\n",
       "      <td>delonixkidal</td>\n",
       "      <td>love for my country  best joke</td>\n",
       "      <td>love for my country  best joke</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79448</th>\n",
       "      <td>79448</td>\n",
       "      <td>1243477119767805952</td>\n",
       "      <td>1243476481679986689</td>\n",
       "      <td>2020-03-27 05:57:02 EDT</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>05:57:02</td>\n",
       "      <td>-500</td>\n",
       "      <td>765214431651463168</td>\n",
       "      <td>ignitedigitalhq</td>\n",
       "      <td>there have been many exciting launches in the tech world this week we thought you might like our roundup</td>\n",
       "      <td>...</td>\n",
       "      <td>ignitedigitalhq</td>\n",
       "      <td>there have been many exciting launches in the tech world this week we thought you might like our roundup</td>\n",
       "      <td>there have been many exciting launches in the tech world this week we thought you might like our roundup</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                   id      conversation_id  \\\n",
       "3465         3465  1338853447324463106  1338511787805773826   \n",
       "79448       79448  1243477119767805952  1243476481679986689   \n",
       "\n",
       "                    created_at        date      time  timezone  \\\n",
       "3465   2020-12-15 09:28:31 EST  2020-12-15  09:28:31      -500   \n",
       "79448  2020-03-27 05:57:02 EDT  2020-03-27  05:57:02      -500   \n",
       "\n",
       "                  user_id         username  \\\n",
       "3465   957772878132498432     delonixkidal   \n",
       "79448  765214431651463168  ignitedigitalhq   \n",
       "\n",
       "                                                                                                                          tweet  \\\n",
       "3465                                                                                             love for my country  best joke   \n",
       "79448                  there have been many exciting launches in the tech world this week we thought you might like our roundup   \n",
       "\n",
       "       ...         username  \\\n",
       "3465   ...     delonixkidal   \n",
       "79448  ...  ignitedigitalhq   \n",
       "\n",
       "                                                                                                                          tweet  \\\n",
       "3465                                                                                             love for my country  best joke   \n",
       "79448                  there have been many exciting launches in the tech world this week we thought you might like our roundup   \n",
       "\n",
       "                                                                                                                 tweet_compound  \\\n",
       "3465                                                                                             love for my country  best joke   \n",
       "79448                  there have been many exciting launches in the tech world this week we thought you might like our roundup   \n",
       "\n",
       "      topic  neg    neu    pos compound month day  \n",
       "3465      2  0.0  0.221  0.779   0.8910    12  15  \n",
       "79448     2  0.0  0.749  0.251   0.6908     3  27  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with option_context('display.max_colwidth', 600):\n",
    "    display(full_df[(full_df['topic']==2)].sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic  month\n",
       "0      1        0.033063\n",
       "       2        0.021700\n",
       "       3        0.021529\n",
       "       4        0.043048\n",
       "       5        0.041482\n",
       "       6       -0.010150\n",
       "       7        0.026898\n",
       "       8        0.009280\n",
       "       9        0.041911\n",
       "       10       0.043748\n",
       "       11       0.025930\n",
       "       12       0.047196\n",
       "1      1        0.068411\n",
       "       2        0.092013\n",
       "       3        0.103172\n",
       "       4        0.057641\n",
       "       5        0.082436\n",
       "       6        0.055252\n",
       "       7        0.088006\n",
       "       8        0.094351\n",
       "       9        0.086824\n",
       "       10       0.104480\n",
       "       11       0.076168\n",
       "       12       0.082135\n",
       "2      1        0.120690\n",
       "       2        0.197029\n",
       "       3        0.166473\n",
       "       4        0.130331\n",
       "       5        0.111652\n",
       "       6        0.079333\n",
       "       7        0.160844\n",
       "       8        0.112680\n",
       "       9        0.143523\n",
       "       10       0.135904\n",
       "       11       0.042663\n",
       "       12       0.185003\n",
       "3      1       -0.048408\n",
       "       2       -0.013104\n",
       "       3        0.021404\n",
       "       4       -0.033855\n",
       "       5       -0.048497\n",
       "       6       -0.069768\n",
       "       7       -0.019075\n",
       "       8       -0.048334\n",
       "       9       -0.041741\n",
       "       10       0.007028\n",
       "       11      -0.042141\n",
       "       12       0.006181\n",
       "4      1        0.163810\n",
       "       2        0.171759\n",
       "       3        0.173495\n",
       "       4        0.146035\n",
       "       5        0.161644\n",
       "       6        0.129668\n",
       "       7        0.165414\n",
       "       8        0.168175\n",
       "       9        0.157002\n",
       "       10       0.165436\n",
       "       11       0.176705\n",
       "       12       0.161894\n",
       "Name: compound, dtype: float64"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby(['topic','month'])['compound'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "0    15334\n",
       "1    22689\n",
       "2    19313\n",
       "3    13987\n",
       "4    27973\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby('topic')['topic'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99296, 34)"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to csv for Tableau analysis\n",
    "full_df.to_csv('datatableau.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFI-DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display top n terms associated with each topic\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tawneykirkland/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'course', 'might', 'must', \"n't\", 'sha', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99296, 14605)\n"
     ]
    }
   ],
   "source": [
    "# tuning vectorizer params\n",
    "tf_idf = TfidfVectorizer(stop_words=stop,\n",
    "                         tokenizer=word_tokenize,\n",
    "                         min_df= 2,\n",
    "                         max_df= 0.9)\n",
    "\n",
    "# document-term matrix\n",
    "doc_word2 = tf_idf.fit_transform(df_analysis.tweet_compound)\n",
    "print(doc_word2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "account, lock, access, months, reason\n",
      "\n",
      "Topic  1\n",
      "help, account, problem, revolut, trying\n",
      "\n",
      "Topic  2\n",
      "app, access, contact, support, new\n",
      "\n",
      "Topic  3\n",
      "waiting, chat, agent, live, reply\n",
      "\n",
      "Topic  4\n",
      "money, revolut, bank, transfer, send\n"
     ]
    }
   ],
   "source": [
    "n = 5 # number of topics\n",
    "\n",
    "# model selection, fit/trans, and hyperparameter tuning\n",
    "nmf_model_2 = NMF(n_components =n)\n",
    "\n",
    "# doc-topic matrix\n",
    "doc_topic2 = nmf_model_2.fit_transform(doc_word2)\n",
    "\n",
    "# creating ids for each topic\n",
    "topic_ids2 = [\"topic\"+str(val) for val in range(n)]\n",
    "\n",
    "# topic-term matrix\n",
    "topic_word2 = pd.DataFrame(nmf_model_2.components_.round(n),\n",
    "             index = topic_ids2,\n",
    "             columns = tf_idf.get_feature_names())\n",
    "\n",
    "# prints top x words in each topic\n",
    "display_topics(nmf_model_2, \n",
    "               tf_idf.get_feature_names(), \n",
    "               5) # number of top words/topic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
